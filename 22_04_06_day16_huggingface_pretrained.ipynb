{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"22_04_06_day16_huggingface_pretrained.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNYDF9rHqXxVgi6iUOKgUx2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ac23cfef6b5a4140b17452510776b7fb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_776761e7115f4746b1e5865107232303","IPY_MODEL_b4213055a84a46d2bfec71d7d6dfef53","IPY_MODEL_0ad8abeaae28428caf33eff80de25d5b"],"layout":"IPY_MODEL_4f49e95537964531a2060cbd72967d2b"}},"776761e7115f4746b1e5865107232303":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc9fe3812ceb45b281f286b0faf627f0","placeholder":"​","style":"IPY_MODEL_40edc441b0fd4d1eba2df3b3e8c82419","value":"Downloading: 100%"}},"b4213055a84a46d2bfec71d7d6dfef53":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0be92658fd4484ba82e34223bce2ec2","max":714314041,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d78c75d0852c403c9581db339dca4cef","value":714314041}},"0ad8abeaae28428caf33eff80de25d5b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8de50edb4864192bacd1ed50a9fed43","placeholder":"​","style":"IPY_MODEL_b2e3b02175c7454082e1b135a5b8b7db","value":" 681M/681M [00:25&lt;00:00, 32.9MB/s]"}},"4f49e95537964531a2060cbd72967d2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc9fe3812ceb45b281f286b0faf627f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40edc441b0fd4d1eba2df3b3e8c82419":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0be92658fd4484ba82e34223bce2ec2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d78c75d0852c403c9581db339dca4cef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b8de50edb4864192bacd1ed50a9fed43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2e3b02175c7454082e1b135a5b8b7db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Lhguys-Nh4E","executionInfo":{"status":"ok","timestamp":1649218972093,"user_tz":-540,"elapsed":16637,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"bf3ab6db-b1f2-4de5-d4d1-1dc9ed78b912"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.0.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.63.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"]}],"source":["!pip install transformers\n","!pip install datasets"]},{"cell_type":"code","source":["!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","!tar -xf aclImdb_v1.tar.gz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NfO_uC5VoZQC","executionInfo":{"status":"ok","timestamp":1649218994927,"user_tz":-540,"elapsed":22839,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"0d2fa77d-8a39-49f5-ebad-4e202ae19443"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-04-06 04:22:51--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n","Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 84125825 (80M) [application/x-gzip]\n","Saving to: ‘aclImdb_v1.tar.gz.1’\n","\n","aclImdb_v1.tar.gz.1 100%[===================>]  80.23M  30.6MB/s    in 2.6s    \n","\n","2022-04-06 04:22:54 (30.6 MB/s) - ‘aclImdb_v1.tar.gz.1’ saved [84125825/84125825]\n","\n"]}]},{"cell_type":"code","source":["import torch\n","from transformers import DistilBertTokenizerFast\n","from transformers import DistilBertConfig\n","from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n","from pathlib import Path\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"2m1dM-xApGaz","executionInfo":{"status":"ok","timestamp":1649218994927,"user_tz":-540,"elapsed":13,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["def read_imdb_split(split_dir):\n","    split_dir = Path(split_dir)\n","    texts = []\n","    labels = []\n","    for label_dir in [\"pos\", \"neg\"]:\n","        for text_file in (split_dir/label_dir).iterdir():\n","            texts.append(text_file.read_text())\n","            labels.append(0 if label_dir is \"neg\" else 1)\n","    return texts, labels"],"metadata":{"id":"Di-89GFyqBDb","executionInfo":{"status":"ok","timestamp":1649218994928,"user_tz":-540,"elapsed":13,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["train_texts, train_labels = read_imdb_split('aclImdb/train')\n","test_texts, test_labels = read_imdb_split('aclImdb/test')"],"metadata":{"id":"yYr1wle8rMJC","executionInfo":{"status":"ok","timestamp":1649218998875,"user_tz":-540,"elapsed":3960,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["#model_name = 'distilbert-base-uncased'\n","tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z9iDfPSerhWo","executionInfo":{"status":"ok","timestamp":1649219000049,"user_tz":-540,"elapsed":1178,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"fc61ae0a-b1be-4965-e50f-7b1dc5e567a0"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["loading file https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","loading file https://huggingface.co/distilbert-base-uncased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/distilbert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.17.0\",\n","  \"vocab_size\": 30522\n","}\n","\n"]}]},{"cell_type":"code","source":["train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.2)"],"metadata":{"id":"l1KHoGHFs35R","executionInfo":{"status":"ok","timestamp":1649219000049,"user_tz":-540,"elapsed":2,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n","val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n","test_encodings = tokenizer(test_texts, truncation=True, padding=True)"],"metadata":{"id":"jHBwm9ZXshTB","executionInfo":{"status":"ok","timestamp":1649219044359,"user_tz":-540,"elapsed":44312,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["print(len(train_encodings))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w_wExW1ktYYX","executionInfo":{"status":"ok","timestamp":1649219044360,"user_tz":-540,"elapsed":18,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"ddf44538-e5bd-4b79-c117-46fefcc62340"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n"]}]},{"cell_type":"code","source":["print(train_encodings[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H_xwzjk6trYo","executionInfo":{"status":"ok","timestamp":1649219044361,"user_tz":-540,"elapsed":16,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"7c3f896b-8c49-4fcf-fd41-7d0b677a690a"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoding(num_tokens=512, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n"]}]},{"cell_type":"code","source":["class IMDbDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","    \n","    def __getitem__(self, idx):\n","        item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","    \n","    def __len__(self):\n","        return len(self.labels)"],"metadata":{"id":"AKYiyHl6uNdw","executionInfo":{"status":"ok","timestamp":1649219044361,"user_tz":-540,"elapsed":15,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["train_dataset = IMDbDataset(train_encodings, train_labels)\n","val_dataset = IMDbDataset(val_encodings, val_labels)\n","test_dataset = IMDbDataset(test_encodings, test_labels)"],"metadata":{"id":"VAKWx_yYu082","executionInfo":{"status":"ok","timestamp":1649219044362,"user_tz":-540,"elapsed":15,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["config = DistilBertConfig.from_pretrained('distilbert-base-uncased',\\\n","                                 vocab_size = 30522, \\\n","                                 max_position_embedding = 512, \\\n","                                 sinusoidal_pos_embds = False, \\\n","                                 n_layer = 4, \\\n","                                 n_heads= 8, \\\n","                                 dim = 768, \\\n","                                 hidden_dim = 3072, \\\n","                                 dropout=0.1, \\\n","                                 attention_dropout= 0.1, \\\n","                                 activation='gelu')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2zV6pgX6vFWu","executionInfo":{"status":"ok","timestamp":1649219044722,"user_tz":-540,"elapsed":375,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"fe43df96-bd09-4f37-a494-8804a14ec74d"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 8,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.17.0\",\n","  \"vocab_size\": 30522\n","}\n","\n"]}]},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir = './results',\n","    num_train_epochs = 1,\n","    per_device_train_batch_size = 16,\n","    per_device_eval_batch_size = 64,\n","    warmup_steps = 500,\n","    weight_decay = 0.01,\n","    logging_dir='./logs',\n","    logging_steps = 100,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uRPQxbhuv8r_","executionInfo":{"status":"ok","timestamp":1649219044722,"user_tz":-540,"elapsed":6,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"614c3be8-3136-45b1-86c1-a601a7726e3f"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}]},{"cell_type":"code","source":["model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', config=config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tsAfYRq3woKm","executionInfo":{"status":"ok","timestamp":1649219046615,"user_tz":-540,"elapsed":1896,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"dbd06698-73f5-4185-b0cb-0e2489969258"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":["loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["trainer = Trainer(\n","    model = model,\n","    args = training_args,\n","    train_dataset = train_dataset,\n","    eval_dataset = val_dataset\n",")\n","\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":865},"id":"XEcO7Dsxwz4t","executionInfo":{"status":"ok","timestamp":1649220776379,"user_tz":-540,"elapsed":1729767,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"1fdf789c-b4f4-48f8-ced2-7a459af8623b"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 20000\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1250\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1250/1250 28:46, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.680900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.414300</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.347300</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.349400</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.345200</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.326100</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.337400</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.258100</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.267300</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.289200</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.251800</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.246400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1250, training_loss=0.340553897857666, metrics={'train_runtime': 1727.8931, 'train_samples_per_second': 11.575, 'train_steps_per_second': 0.723, 'total_flos': 2649347973120000.0, 'train_loss': 0.340553897857666, 'epoch': 1.0})"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["from datasets import load_metric\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm"],"metadata":{"id":"3nWxI8JlxGle","executionInfo":{"status":"ok","timestamp":1649220776380,"user_tz":-540,"elapsed":15,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["metric = load_metric(\"accuracy\")\n","test_dataloader = DataLoader(test_dataset, batch_size=128)\n","model.eval()\n","\n","for batch in tqdm(test_dataloader):\n","    batch = {k : v.to(\"cuda\") for k, v in batch.items()}\n","    with torch.no_grad():\n","        outputs = model(**batch)\n","    logits = outputs.logits\n","    predictions = torch.argmax(logits, dim=-1)\n","    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n","\n","metric.compute()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sv0eelji1O9-","executionInfo":{"status":"ok","timestamp":1649221572609,"user_tz":-540,"elapsed":796235,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"b9090581-d3e4-4810-fea7-e0a9cac0e04e"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 196/196 [13:15<00:00,  4.06s/it]\n"]},{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 0.91636}"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","source":["# Bert기반 MRC"],"metadata":{"id":"XeuWrdR-WYKt"}},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LNso4LdH14Mc","executionInfo":{"status":"ok","timestamp":1649223006799,"user_tz":-540,"elapsed":6230,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"904f338d-d139-4de1-8b13-59d087143c51"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"]}]},{"cell_type":"code","source":["import torch\n","import sys"],"metadata":{"id":"3hp0UvpgWeCU","executionInfo":{"status":"ok","timestamp":1649223024916,"user_tz":-540,"elapsed":234,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"7Geatl40Wj7V","executionInfo":{"status":"ok","timestamp":1649223067346,"user_tz":-540,"elapsed":219,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["!wget https://aistages-prod-server-public.s3.amazonaws.com/app/Competitions/000072/data/klue-mrc-v1.1.tar.gz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uSk6L9pDWuSd","executionInfo":{"status":"ok","timestamp":1649223081466,"user_tz":-540,"elapsed":1850,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"d41eb37d-b3f9-49c8-c04e-be72c229bbda"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-04-06 05:31:19--  https://aistages-prod-server-public.s3.amazonaws.com/app/Competitions/000072/data/klue-mrc-v1.1.tar.gz\n","Resolving aistages-prod-server-public.s3.amazonaws.com (aistages-prod-server-public.s3.amazonaws.com)... 52.218.197.163\n","Connecting to aistages-prod-server-public.s3.amazonaws.com (aistages-prod-server-public.s3.amazonaws.com)|52.218.197.163|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 19217651 (18M) [application/x-gzip]\n","Saving to: ‘klue-mrc-v1.1.tar.gz’\n","\n","klue-mrc-v1.1.tar.g 100%[===================>]  18.33M  20.8MB/s    in 0.9s    \n","\n","2022-04-06 05:31:21 (20.8 MB/s) - ‘klue-mrc-v1.1.tar.gz’ saved [19217651/19217651]\n","\n"]}]},{"cell_type":"code","source":["!tar zxfv \"/content/klue-mrc-v1.1.tar.gz\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hTMhRvrRWxVt","executionInfo":{"status":"ok","timestamp":1649223119342,"user_tz":-540,"elapsed":1081,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"ecd53428-b8ee-41a7-c605-1222d5ccc110"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["klue-mrc-v1.1/\n","klue-mrc-v1.1/klue-mrc-v1.1_dev.json\n","klue-mrc-v1.1/klue-mrc-v1.1_train.json\n","klue-mrc-v1.1/klue-mrc-v1.1_dev_sample_10.json\n"]}]},{"cell_type":"code","source":["import json\n","from pathlib import Path"],"metadata":{"id":"qrNV6lbpXUi0","executionInfo":{"status":"ok","timestamp":1649223303681,"user_tz":-540,"elapsed":237,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["def read_squad(path):\n","    path = Path(path)\n","    with open(path, 'rb') as f:\n","        squad_dict = json.load(f)\n","    \n","    contexts = []\n","    questions = []\n","    answers = []\n","\n","    for group in squad_dict['data']:\n","        for passage in group['paragraphs']:\n","            context = passage['context']\n","            for qa in passage['qas']:\n","                question = qa['question']\n","                for answer in qa['answers']:\n","                    contexts.append(context)\n","                    questions.append(question)\n","                    answers.append(answer)\n","    return contexts, questions, answers"],"metadata":{"id":"bUP1bM42Xn-8","executionInfo":{"status":"ok","timestamp":1649223485831,"user_tz":-540,"elapsed":251,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["train_contexts, train_questions, train_answers = read_squad('/content/klue-mrc-v1.1/klue-mrc-v1.1_train.json')\n","val_contexts, val_questions, val_answers = read_squad('/content/klue-mrc-v1.1/klue-mrc-v1.1_dev.json')"],"metadata":{"id":"gv96jfn4YTOz","executionInfo":{"status":"ok","timestamp":1649223617389,"user_tz":-540,"elapsed":1265,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["print('1. train data')\n","print(len(train_contexts))\n","print(len(train_questions))\n","print(len(train_answers))\n","print('\\n')\n","print('2. validation data')\n","print(len(val_contexts))\n","print(len(val_questions))\n","print(len(val_answers))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7bD0sqDiY0UT","executionInfo":{"status":"ok","timestamp":1649223696275,"user_tz":-540,"elapsed":230,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"983af46d-4816-45eb-c655-181d6e4710af"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["1. train data\n","17663\n","17663\n","17663\n","\n","\n","2. validation data\n","5811\n","5811\n","5811\n"]}]},{"cell_type":"code","source":["print(train_contexts[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T6gf7MH6ZH1U","executionInfo":{"status":"ok","timestamp":1649223772489,"user_tz":-540,"elapsed":271,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"2f0ef288-eaee-40ea-9c99-29e37e88f675"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은 이달 말께 장마가 시작될 전망이다.17일 기상청에 따르면 제주도 남쪽 먼바다에 있는 장마전선의 영향으로 이날 제주도 산간 및 내륙지역에 호우주의보가 내려지면서 곳곳에 100㎜에 육박하는 많은 비가 내렸다. 제주의 장마는 평년보다 2~3일, 지난해보다는 하루 일찍 시작됐다. 장마는 고온다습한 북태평양 기단과 한랭 습윤한 오호츠크해 기단이 만나 형성되는 장마전선에서 내리는 비를 뜻한다.장마전선은 18일 제주도 먼 남쪽 해상으로 내려갔다가 20일께 다시 북상해 전남 남해안까지 영향을 줄 것으로 보인다. 이에 따라 20~21일 남부지방에도 예년보다 사흘 정도 장마가 일찍 찾아올 전망이다. 그러나 장마전선을 밀어올리는 북태평양 고기압 세력이 약해 서울 등 중부지방은 평년보다 사나흘가량 늦은 이달 말부터 장마가 시작될 것이라는 게 기상청의 설명이다. 장마전선은 이후 한 달가량 한반도 중남부를 오르내리며 곳곳에 비를 뿌릴 전망이다. 최근 30년간 평균치에 따르면 중부지방의 장마 시작일은 6월24~25일이었으며 장마기간은 32일, 강수일수는 17.2일이었다.기상청은 올해 장마기간의 평균 강수량이 350~400㎜로 평년과 비슷하거나 적을 것으로 내다봤다. 브라질 월드컵 한국과 러시아의 경기가 열리는 18일 오전 서울은 대체로 구름이 많이 끼지만 비는 오지 않을 것으로 예상돼 거리 응원에는 지장이 없을 전망이다.\n"]}]},{"cell_type":"code","source":["print(len(train_contexts[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"voW8KxUaZabN","executionInfo":{"status":"ok","timestamp":1649223795021,"user_tz":-540,"elapsed":217,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"ce3683de-a8f2-47dc-eaf3-0949bd9c1c05"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["728\n"]}]},{"cell_type":"code","source":["print(train_questions[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ApC8LhWSZf8M","executionInfo":{"status":"ok","timestamp":1649223811904,"user_tz":-540,"elapsed":244,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"3b330d77-3595-4822-f700-ca030d9f2858"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은?\n"]}]},{"cell_type":"code","source":["print(train_answers[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cSQ-vU-7ZkCM","executionInfo":{"status":"ok","timestamp":1649223828145,"user_tz":-540,"elapsed":243,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"e012829c-ab21-41a4-dbb3-eacfab0f40fb"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["{'text': '한 달가량', 'answer_start': 478}\n"]}]},{"cell_type":"code","source":["def add_end_idx(answers, contexts):\n","    for answer, context in zip(answers, contexts):\n","        gold_text = answer['text']\n","        start_idx = answer['answer_start']\n","        end_idx = start_idx + len(gold_text)\n","\n","        # 이순신은 조선 중기의 무신이다. '이순신' start 0, end 4\n","        if context[start_idx: end_idx] == gold_text:\n","            answer['answer_end'] = end_idx\n","        elif context[start_idx -1 : end_idx - 1] == gold_text:\n","            answer['answer_end'] = end_idx-1\n","        elif context[start_idx -2 : end_idx - 2] == gold_text:\n","            answer['answer_end'] = end_idx-2\n","    return answers"],"metadata":{"id":"bDc4Mi4xZoBk","executionInfo":{"status":"ok","timestamp":1649225533275,"user_tz":-540,"elapsed":232,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["train_answers = add_end_idx(train_answers, train_contexts)\n","val_answers = add_end_idx(val_answers, val_contexts)"],"metadata":{"id":"6coI9f25f4Ug","executionInfo":{"status":"ok","timestamp":1649225534893,"user_tz":-540,"elapsed":308,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoModel, AutoTokenizer, BertTokenizer"],"metadata":{"id":"0S8BN_lTgEF5","executionInfo":{"status":"ok","timestamp":1649225569639,"user_tz":-540,"elapsed":241,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["model_name = 'bert-base-multilingual-cased'\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n","val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rjgVX1s9gRMp","executionInfo":{"status":"ok","timestamp":1649225703804,"user_tz":-540,"elapsed":24473,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"59558a93-3380-4eff-aa85-8737e2209be5"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-multilingual-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 119547\n","}\n","\n","loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n","loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46880f3b0081fda494a4e15b05787692aa4c1e21e0ff2428ba8b14d4eda0784d.b33e51591f94f17c238ee9b1fac75b96ff2678cbaed6e108feadb3449d18dc24\n","loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n","loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-multilingual-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 119547\n","}\n","\n"]}]},{"cell_type":"code","source":["def add_token_positions(encodings, answers):\n","    start_positions = []\n","    end_positions = []\n","\n","    for i in range(len(answers)):\n","        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n","        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n","\n","        # truncation하는 부분\n","        if start_positions[-1] is None:\n","            start_positions[-1] = tokenizer.model_max_length\n","        \n","        if end_positions[-1] is None:\n","            end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end'] + 1)\n","\n","        if start_positions[-1] is None or start_positions[-1] > tokenizer.model_max_length:\n","            start_positions[-1] = tokenizer.model_max_length\n","        \n","        if end_positions[-1] is None or end_positions[-1] > tokenizer.model_max_length:\n","            end_positions[-1] = tokenizer.model_max_length\n","\n","    encodings.update({'start_positions' : start_positions, 'end_positions' : end_positions})\n","    return encodings"],"metadata":{"id":"TVrbCeVJgpe5","executionInfo":{"status":"ok","timestamp":1649226203774,"user_tz":-540,"elapsed":235,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["train_encodings = add_token_positions(train_encodings, train_answers)\n","val_encodings = add_token_positions(val_encodings, val_answers)"],"metadata":{"id":"6qop6t6JifbP","executionInfo":{"status":"ok","timestamp":1649226205167,"user_tz":-540,"elapsed":372,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","class SquadDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings):\n","        self.encodings = encodings\n","\n","    def __getitem__(self, idx):\n","        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","\n","    def __len__(self):\n","        return len(self.encodings.input_ids)"],"metadata":{"id":"Cv4Evmp2ipPA","executionInfo":{"status":"ok","timestamp":1649226341599,"user_tz":-540,"elapsed":357,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["train_dataset = SquadDataset(train_encodings)\n","val_dataset = SquadDataset(val_encodings)"],"metadata":{"id":"j4dpiGgQjNoY","executionInfo":{"status":"ok","timestamp":1649226374077,"user_tz":-540,"elapsed":236,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["from transformers import BertForQuestionAnswering\n","model = BertForQuestionAnswering.from_pretrained(model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":817,"referenced_widgets":["ac23cfef6b5a4140b17452510776b7fb","776761e7115f4746b1e5865107232303","b4213055a84a46d2bfec71d7d6dfef53","0ad8abeaae28428caf33eff80de25d5b","4f49e95537964531a2060cbd72967d2b","dc9fe3812ceb45b281f286b0faf627f0","40edc441b0fd4d1eba2df3b3e8c82419","e0be92658fd4484ba82e34223bce2ec2","d78c75d0852c403c9581db339dca4cef","b8de50edb4864192bacd1ed50a9fed43","b2e3b02175c7454082e1b135a5b8b7db"]},"id":"8S5ZABmtjVlf","executionInfo":{"status":"ok","timestamp":1649226458199,"user_tz":-540,"elapsed":28704,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"fe6cf928-7e76-4429-fb95-7f1de7175ebd"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 119547\n","}\n","\n","https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp0rof57ww\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/681M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac23cfef6b5a4140b17452510776b7fb"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["storing https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n","creating metadata file for /root/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n","loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n","Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForQuestionAnswering: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["from transformers import BertForQuestionAnswering, Trainer, TrainingArguments\n","import sys\n","\n","training_args = TrainingArguments(\n","    output_dir = './result',\n","    num_train_epochs = 1,\n","    per_device_train_batch_size = 8,\n","    per_device_eval_batch_size = 64,\n","    logging_dir = './logs',\n","    logging_steps = 100,\n","    learning_rate=3e-5,\n","    save_total_limit=5\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8fX2FhfFjhbf","executionInfo":{"status":"ok","timestamp":1649226618488,"user_tz":-540,"elapsed":284,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"ed13afc8-e9e0-425b-8fc3-053fca78e4e3"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}]},{"cell_type":"code","source":["model = BertForQuestionAnswering.from_pretrained(model_name)\n","model.to(device)\n","\n","trainer = Trainer(\n","    model= model,\n","    args = training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9S9lyi0KkNAX","executionInfo":{"status":"ok","timestamp":1649226698548,"user_tz":-540,"elapsed":4472,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"3f0e4667-a253-48d0-faa7-0a5a4bc56c0a"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 119547\n","}\n","\n","loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n","Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForQuestionAnswering: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["trainer.train() # 1 epoch 한 시간걸림"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"9mziQNgwkjxX","executionInfo":{"status":"ok","timestamp":1649230103667,"user_tz":-540,"elapsed":3383419,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"45c4bf84-35a9-449c-c64f-a3aa5fb4111e"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 17663\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2208\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2208' max='2208' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2208/2208 56:21, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>4.199900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>3.210600</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>2.754000</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>2.624000</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>2.403600</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>2.374100</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>2.375900</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>2.188200</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>2.192400</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.115700</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>2.201300</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>2.130400</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>1.963300</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>2.049600</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.934500</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>1.835500</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>1.903800</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>1.742800</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>1.892200</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.861600</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>1.797100</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>1.699600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to ./result/checkpoint-500\n","Configuration saved in ./result/checkpoint-500/config.json\n","Model weights saved in ./result/checkpoint-500/pytorch_model.bin\n","Saving model checkpoint to ./result/checkpoint-1000\n","Configuration saved in ./result/checkpoint-1000/config.json\n","Model weights saved in ./result/checkpoint-1000/pytorch_model.bin\n","Saving model checkpoint to ./result/checkpoint-1500\n","Configuration saved in ./result/checkpoint-1500/config.json\n","Model weights saved in ./result/checkpoint-1500/pytorch_model.bin\n","Saving model checkpoint to ./result/checkpoint-2000\n","Configuration saved in ./result/checkpoint-2000/config.json\n","Model weights saved in ./result/checkpoint-2000/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=2208, training_loss=2.2457217470459314, metrics={'train_runtime': 3383.0354, 'train_samples_per_second': 5.221, 'train_steps_per_second': 0.653, 'total_flos': 4615284614227968.0, 'train_loss': 2.2457217470459314, 'epoch': 1.0})"]},"metadata":{},"execution_count":75}]},{"cell_type":"code","source":["trainer.save_model(\".\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qmghe1-qkqCf","executionInfo":{"status":"ok","timestamp":1649230963177,"user_tz":-540,"elapsed":3114,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"c06b0f9d-0a92-469b-c057-2c3c7bbcc4c4"},"execution_count":76,"outputs":[{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to .\n","Configuration saved in ./config.json\n","Model weights saved in ./pytorch_model.bin\n"]}]},{"cell_type":"code","source":["from transformers import pipeline"],"metadata":{"id":"Bajt6LPr01Q_","executionInfo":{"status":"ok","timestamp":1649231009538,"user_tz":-540,"elapsed":1137,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"execution_count":77,"outputs":[]},{"cell_type":"code","source":["nlp = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device = 0)"],"metadata":{"id":"gkJp9V2M1BEg","executionInfo":{"status":"ok","timestamp":1649231039230,"user_tz":-540,"elapsed":995,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"execution_count":78,"outputs":[]},{"cell_type":"code","source":["context = r\"\"\"\n","이순신(李舜臣, 1545년 4월 28일 ~ 1598년 12월 16일 (음력 11월 19일))은 조선 중기의 무신이었다.\n","본관은 덕수(德水), 자는 여해(汝諧), 시호는 충무(忠武)였으며, 한성 출신이었다.\n","문반 가문 출신으로 1576년(선조 9년) 무과(武科)에 급제하여 그 관직이 동구비보 권관, 훈련원 봉사, 발포진 수군만호, 조산보 만호, 전라좌도 수군절도사를 거쳐 정헌대부 삼도수군통제사에 이르렀다.\n","\"\"\""],"metadata":{"id":"T0E1CWag1IXA","executionInfo":{"status":"ok","timestamp":1649231065027,"user_tz":-540,"elapsed":228,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["nlp(question=\"이순신이 태어난 날짜는?\", context=context)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ShXF4RhI1O2H","executionInfo":{"status":"ok","timestamp":1649231096434,"user_tz":-540,"elapsed":229,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"5ab8f6aa-0cbd-4be3-bc4d-b571339d4661"},"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answer': '음력 11월 19일)', 'end': 51, 'score': 0.01598655804991722, 'start': 40}"]},"metadata":{},"execution_count":80}]},{"cell_type":"code","source":["nlp(question=\"이순신이 본관은?\", context=context)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BLHKvR3q1Wg4","executionInfo":{"status":"ok","timestamp":1649231127712,"user_tz":-540,"elapsed":244,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"90830a58-e77f-4504-ad6c-45f6d862bb11"},"execution_count":81,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answer': '李舜臣,', 'end': 9, 'score': 0.0046199019998312, 'start': 5}"]},"metadata":{},"execution_count":81}]},{"cell_type":"code","source":["nlp(question=\"이순신이 시호은?\", context=context)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8zUoOH1s1eI6","executionInfo":{"status":"ok","timestamp":1649231153796,"user_tz":-540,"elapsed":261,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"814db20c-a507-420f-ff15-3c01621162b7"},"execution_count":82,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answer': '汝諧), 시호는 충무(忠武)',\n"," 'end': 101,\n"," 'score': 0.00594160333275795,\n"," 'start': 86}"]},"metadata":{},"execution_count":82}]},{"cell_type":"code","source":["nlp(question=\"이순신이 고향은?\", context=context)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IN_we8rZ1kgi","executionInfo":{"status":"ok","timestamp":1649231169003,"user_tz":-540,"elapsed":234,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"d1ebba69-bbe2-4e21-f939-7fbacd968ea0"},"execution_count":83,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answer': '1598년 12월', 'end': 34, 'score': 0.03868522867560387, 'start': 25}"]},"metadata":{},"execution_count":83}]},{"cell_type":"code","source":["nlp(question=\"이순신이 마지막 직책은?\", context=context)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tIC7sa2K1oOS","executionInfo":{"status":"ok","timestamp":1649231198207,"user_tz":-540,"elapsed":223,"user":{"displayName":"백혜림","userId":"01884416935170274848"}},"outputId":"5f62b0b6-65f6-40d1-ac73-717f22f57c45"},"execution_count":86,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answer': '정헌대부 삼도수군통제사에',\n"," 'end': 222,\n"," 'score': 0.006898166611790657,\n"," 'start': 209}"]},"metadata":{},"execution_count":86}]},{"cell_type":"code","source":[""],"metadata":{"id":"pPreJvXM1tF6"},"execution_count":null,"outputs":[]}]}